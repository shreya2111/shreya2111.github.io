---
title:  "GSoC 2019 - Extending Gentle Aligner"
date:   2019-07-03
layout: default
author_profile: false
comments: false
tags: [GSoC, ASR, Forced-Alignment]
category: GSoC
permalink: "gsoc/gsocWk5"
---

![GSoC](/icons/GSoC.png)

<h1> Extending Gentle Aligner </h1>
<h2> Week 5 </h2>
<h4> Groundwork for Generating a Language Model </h4>

* Now that we know how to generate forced-alignements for utterances using Kaldi, we shift our focus to generating a customized langauge model that would probably increase the accuracy of the forced alignment.

* What is a Language Model made of?

  The kind of language model that we are aiming to build will be specific to an utterance of an audio file. In other words, each utterance will have a language model of its own. To build a language model, we will require followng inputs:

        1. lexicon or dictionary [lexicon.txt, words.txt]
        2. phonemes [nonsilence_phones.txt, optional_silence.txt, silence_phones.txt]
        3. grammar [G.fst]

* Building a lexicon or a dictionary

    Given that creating a lexicon could be a tedious task for a new language, we have a new challenge where we would need 
    a lexicon for each utterance, and that would need to be generated on the go as an utterance is provided. 

    There are two ways in which we can generate a lexicon from an utterance:

        1. Using a simple python script [located here]

            It takes an utterance, breaks it up into words and looks up the words in an even bigger dictionary/lexicon of the language.

        2. Using g2p-seq2seq library 

            Therefore, grapheme2phoneme library seems like an useful tool that can be pre-trained on any langauge's lexicon (all possible words in a langauge) and then it can produce a lexicon specific to a text. [Link to g2p library](https://github.com/cmusphinx/g2p-seq2seq)

            install virtualenv (will make your life easier)
            install g2p dependencies
            instal g2p-seq2seq

            train your lexicon using g2p-seq2seq

* Generating Phonemes from Lexicon 

    run ./script/phones.sh path-to/lexicon.txt
    The three file that we need to generate are nonsilence_phones.txt, silence_phones.txt, optional_phones.txt

* Finishing with putting all input files together na dgenerating L.fst, symbol-integer mapped dictionary and phones.txt etc.

     This script provides L.fst, words.txt, phones.txt, topo, L_disambig.fst, oov.txt, oov.int, phones.

        ./utils/prepare_lang.sh data/local/dict/ <UNK> data/local/lang/ data/langdir/

        data/local/dict/
                        lexicon.txt
                        nonsilence_phones.txt
                        silence_phones.txt
                        optional_phones.txt
        data/local/lang/
                        align_lexicon.txt
                        lex_ndisambig
                        lexiconp.txt
                        lexiconp_disambig.txt
                        phone_map.txt
        data/langdir/
                        L.fst
                        L_disambig.fst
                        words.txt
                        phones.txt
                        topo
                        oov.txt
                        oov.int
                        phones/

    Above given directory structure is what you should follow for easy integration with Gentle code for generating the langauge model.
    Make sure to copy langdir/words.txt to tdnn_7b_chain_online/words.txt. Gnetle expects words.txt inside `tdnn_7b_chain_online` directory.

* Next: Generating the language model [Week 6](https://shreya2111.github.io/gsocWk6)

Tools:
Kaldi, Python libraries, C++

References:
 For generating phoneme files [using this blog]((https://www.eleanorchodroff.com/tutorial/kaldi/training-acoustic-models.html#create-files-for-datalocallang))

Link to [GSoC Project Repository](https://github.com/shreya2111/Gentle-Aligner-Extension)
 
