---
title:  "GSoC 2019 - Extending Gentle Aligner"
date:   2019-07-14
layout: default
author_profile: false
comments: false
tags: [GSoC, ASR, Forced-Alignment]
category: GSoC
permalink: "gsoc/gsocWk6"
---

![GSoC](/icons/GSoC.png)

<h1> Extending Gentle Aligner </h1>
<h2> Week 6 </h2>
<h4> Generating a Language Model </h4>

*  Preparing for integration with Gentle Aligner  
    Acoustic model:

        * Pick final.mdl and tree for the langauge that you want to build langauge model for.
        * Place final.mdl inside data/tdnn_7b_chain_online/
        * Place tree inside data/tdnn_7b_chain_online/

    Lexicon:
        * Place words.txt inside data/tdnn_7b_chain_online/graph_pp/words.txt

* Did we get HCLG.fst?

    run script generateLM.py with three arguments, 
        1. path to the utterance.txt 
        2. proto_dir: path to the `data` directory containing `langdir` and `tdnn_7b_chain_online`
        3. path toa pristine copy of Kaldi

    Ex: python3 generateLM.py path-to/utterance.txt path-to/data
    This script calls langauge_model functions of Gentle which generate a bigram grammar G.fst, and compiles L.fst, C.fst and G.fst into HCLG.fst.

        Inputs taken by Gentle are:
           langdir/L.fst
           langdir/L_disambig.fst
		   langdir/phones/disambig.int
		   tdnn_7b_chain_online/final.mdl
		   tdnn_7b_chain_online/tree
		   tdnn_7b_chain_online/graph_pp/words.txt

* After this step you would have generated temp_HCLG.fst which gets saved as `tdnn_7b_chain_online/graph_pp/HCLG.fst`. This `HCLG.fst` will be used in the next step of decoding utterances and producing their word & phoneme level alignments.

* Next: Decoding using an utterance-level-customized langauge model [Week 7](https://shreya2111.github.io/gsocWk7)
* Prev: Summary [Week 5](https://shreya2111.github.io/gsoc/gsocwk5)
* [main page](https://shreya2111.github.io/gsoc)

Tools:
Kaldi, Python, C, Bash Scripting

Link to [GSoC Project Repository](https://github.com/shreya2111/gentle-labs)
 
